{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l69dRL59L5aI",
        "outputId": "b1da5333-5ea4-4acd-b14a-7b98f2f17138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All libraries imported successfully!\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import all required libraries\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from collections import Counter\n",
        "import pickle\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrq4hinkNtAh",
        "outputId": "4e746fe9-73b7-43b8-8aa7-24f7bb5fc166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Successfully loaded 5 documents from /content/COMBINED_CONTRACTS.json\n",
            "\n",
            "üìä First document sample:\n",
            "Filename: ACS_PARTNERSHIP_AGREEMENT.pdf\n",
            "Content preview: synthetic partnership agreements letter 1  partnership agreement partnership agreement example this ...\n",
            "\n",
            "Total documents: 5\n",
            "\n",
            "üìÅ Filename examples: ['ACS_PARTNERSHIP_AGREEMENT.pdf', 'ACS_VENDOR_AGREEMENT.pdf', 'ACS_EMPLOYMENT_CONTRACT.pdf', 'ACS_NDA.pdf', 'ACS_SLA.pdf']...\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Load and inspect the JSON data\n",
        "def load_json_data(file_path):\n",
        "    \"\"\"Load contract data from JSON file\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"‚úÖ Successfully loaded {len(data)} documents from {file_path}\")\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Error: File '{file_path}' not found!\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"‚ùå Error: Invalid JSON format in file '{file_path}'!\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading file: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load your data (update the path as needed)\n",
        "json_file_path = '/content/COMBINED_CONTRACTS.json'  # Change this to your actual path\n",
        "data = load_json_data(json_file_path)\n",
        "\n",
        "if data is not None:\n",
        "    print(f\"\\nüìä First document sample:\")\n",
        "    print(f\"Filename: {data[0]['filename']}\")\n",
        "    print(f\"Content preview: {data[0]['content'][:100]}...\")\n",
        "    print(f\"\\nTotal documents: {len(data)}\")\n",
        "\n",
        "    # Show filename distribution\n",
        "    filenames = [item['filename'] for item in data]\n",
        "    print(f\"\\nüìÅ Filename examples: {filenames[:5]}...\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot proceed without data\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_vk7U5gN-CT",
        "outputId": "ea65aabe-df05-45c6-f2fa-edcdac20b32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Contract Type Distribution:\n",
            "   Partnership: 1 documents\n",
            "   Vendor: 1 documents\n",
            "   Employment: 1 documents\n",
            "   NDA: 1 documents\n",
            "   Service: 1 documents\n",
            "\n",
            "üìà Total labeled documents: 5\n",
            "‚ùì Unknown documents: 0\n",
            "\n",
            "üîç Examples of each contract type:\n",
            "   Partnership: ACS_PARTNERSHIP_AGREEMENT.pdf\n",
            "   Service: ACS_SLA.pdf\n",
            "   NDA: ACS_NDA.pdf\n",
            "   Employment: ACS_EMPLOYMENT_CONTRACT.pdf\n",
            "   Vendor: ACS_VENDOR_AGREEMENT.pdf\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Extract contract types from filenames and analyze\n",
        "def extract_contract_type(filename):\n",
        "    \"\"\"Extract contract type from filename with more patterns\"\"\"\n",
        "    filename_upper = filename.upper()\n",
        "\n",
        "    # More comprehensive pattern matching\n",
        "    if any(keyword in filename_upper for keyword in ['PARTNERSHIP', 'PARTNER']):\n",
        "        return 'Partnership'\n",
        "    elif any(keyword in filename_upper for keyword in ['VENDOR', 'SUPPLIER', 'PROCUREMENT']):\n",
        "        return 'Vendor'\n",
        "    elif any(keyword in filename_upper for keyword in ['EMPLOYMENT', 'EMPLOYEE', 'JOB', 'HIRE']):\n",
        "        return 'Employment'\n",
        "    elif any(keyword in filename_upper for keyword in ['NDA', 'NON_DISCLOSURE', 'CONFIDENTIALITY']):\n",
        "        return 'NDA'\n",
        "    elif any(keyword in filename_upper for keyword in ['SLA', 'SERVICE', 'SUPPORT', 'MAINTENANCE']):\n",
        "        return 'Service'\n",
        "    elif any(keyword in filename_upper for keyword in ['LEASE', 'RENTAL', 'RENT']):\n",
        "        return 'Lease'\n",
        "    elif any(keyword in filename_upper for keyword in ['PURCHASE', 'SALE', 'BUY', 'SELL']):\n",
        "        return 'Purchase'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "# Extract contract types\n",
        "contract_types = []\n",
        "for item in data:\n",
        "    contract_type = extract_contract_type(item['filename'])\n",
        "    contract_types.append(contract_type)\n",
        "\n",
        "print(\"üìã Contract Type Distribution:\")\n",
        "type_counter = Counter(contract_types)\n",
        "for contract_type, count in type_counter.items():\n",
        "    print(f\"   {contract_type}: {count} documents\")\n",
        "\n",
        "print(f\"\\nüìà Total labeled documents: {sum(type_counter.values())}\")\n",
        "print(f\"‚ùì Unknown documents: {type_counter.get('Unknown', 0)}\")\n",
        "\n",
        "# Show examples of each type\n",
        "print(\"\\nüîç Examples of each contract type:\")\n",
        "for contract_type in set(contract_types):\n",
        "    if contract_type != 'Unknown':\n",
        "        example_idx = next(i for i, ct in enumerate(contract_types) if ct == contract_type)\n",
        "        print(f\"   {contract_type}: {data[example_idx]['filename']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRv9--QCOCck",
        "outputId": "905f7d6b-c2d4-47d9-e603-a1be656c4998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßπ Text Preprocessing Test:\n",
            "Original: synthetic partnership agreements letter 1  partnership agreement partnership agreement example this partnership agreement is made this  day of , 20, by and between the following individuals:  address:\n",
            "Cleaned: synthetic partnership agreements letter 1 partnership agreement partnership agreement example this partnership agreement is made this day of   20  by and between the following individuals  address\n",
            "\n",
            "üìä Processed 5 documents for training\n",
            "üìä Skipped 0 documents with unknown types\n",
            "üìä Label distribution: Counter({'Partnership': 1, 'Vendor': 1, 'Employment': 1, 'NDA': 1, 'Service': 1})\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Text preprocessing and cleaning\n",
        "def advanced_preprocess_text(text):\n",
        "    \"\"\"Enhanced text preprocessing\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Replace common legal abbreviations\n",
        "    legal_replacements = {\n",
        "        'inc.': 'incorporated',\n",
        "        'llc': 'limited liability company',\n",
        "        'ltd.': 'limited',\n",
        "        'corp.': 'corporation',\n",
        "        '&': 'and',\n",
        "        'w/': 'with',\n",
        "        'w/o': 'without'\n",
        "    }\n",
        "\n",
        "    for abbrev, full_form in legal_replacements.items():\n",
        "        text = text.replace(abbrev, full_form)\n",
        "\n",
        "    # Remove extra whitespace and newlines\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Remove special characters but keep important legal terms\n",
        "    text = re.sub(r'[^\\w\\s-]', ' ', text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Test preprocessing on a sample\n",
        "sample_text = data[0]['content'][:200] if data else \"Sample contract text with Inc. & LLC\"\n",
        "cleaned_sample = advanced_preprocess_text(sample_text)\n",
        "\n",
        "print(\"üßπ Text Preprocessing Test:\")\n",
        "print(f\"Original: {sample_text}\")\n",
        "print(f\"Cleaned: {cleaned_sample}\")\n",
        "\n",
        "# Preprocess all documents\n",
        "documents = []\n",
        "labels = []\n",
        "unknown_count = 0\n",
        "\n",
        "for i, item in enumerate(data):\n",
        "    contract_type = extract_contract_type(item['filename'])\n",
        "    if contract_type != 'Unknown':\n",
        "        cleaned_content = advanced_preprocess_text(item['content'])\n",
        "        documents.append(cleaned_content)\n",
        "        labels.append(contract_type)\n",
        "    else:\n",
        "        unknown_count += 1\n",
        "\n",
        "print(f\"\\nüìä Processed {len(documents)} documents for training\")\n",
        "print(f\"üìä Skipped {unknown_count} documents with unknown types\")\n",
        "print(f\"üìä Label distribution: {Counter(labels)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lfY1U-HOJ28",
        "outputId": "23aa2677-1d44-4045-9176-65937d093bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Creating TF-IDF vectors...\n",
            "‚úÖ TF-IDF transformation complete!\n",
            "üìê Feature matrix shape: (5, 576)\n",
            "üî† Number of features (words/ngrams): 576\n",
            "üìÑ Number of documents: 5\n",
            "\n",
            "üî§ Sample feature names: ['able' 'access' 'accordance' 'accordance provisions' 'according'\n",
            " 'account' 'acknowledges' 'act' 'actually' 'addition' 'additional'\n",
            " 'additional services' 'address' 'advance' 'agency' 'agree' 'agreed'\n",
            " 'agreement agreement' 'agreement agreement effective' 'agreement cause']...\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Create TF-IDF vectors and analyze features\n",
        "def create_enhanced_tfidf():\n",
        "    \"\"\"Create TF-IDF vectorizer with legal document optimizations\"\"\"\n",
        "    # Legal stop words to consider\n",
        "    legal_stopwords = [\n",
        "        'shall', 'may', 'must', 'will', 'agreement', 'party', 'parties',\n",
        "        'thereof', 'hereof', 'hereby', 'herein', 'whereas', 'therefore',\n",
        "        'said', 'such', 'any', 'all', 'each', 'every', 'other', 'same'\n",
        "    ]\n",
        "\n",
        "    return TfidfVectorizer(\n",
        "        max_features=2000,\n",
        "        ngram_range=(1, 3),  # Include trigrams for legal phrases\n",
        "        stop_words='english',\n",
        "        min_df=2,  # Only include terms that appear in at least 2 documents\n",
        "        max_df=0.95,  # Exclude terms that appear in more than 95% of documents\n",
        "        sublinear_tf=True,  # Use sublinear TF scaling\n",
        "        lowercase=True,\n",
        "        token_pattern=r'\\b[a-zA-Z]{2,}\\b'  # Only words with 2+ letters\n",
        "    )\n",
        "\n",
        "# Create and fit TF-IDF\n",
        "tfidf = create_enhanced_tfidf()\n",
        "print(\"üîß Creating TF-IDF vectors...\")\n",
        "X = tfidf.fit_transform(documents)\n",
        "\n",
        "print(f\"‚úÖ TF-IDF transformation complete!\")\n",
        "print(f\"üìê Feature matrix shape: {X.shape}\")\n",
        "print(f\"üî† Number of features (words/ngrams): {X.shape[1]}\")\n",
        "print(f\"üìÑ Number of documents: {X.shape[0]}\")\n",
        "\n",
        "# Show some feature names\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "print(f\"\\nüî§ Sample feature names: {feature_names[:20]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3PZtRX1ON88",
        "outputId": "7dd7f0fd-1051-47dd-9336-737a6729e0a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Training Logistic Regression classifier...\n",
            "‚úÖ Training complete!\n",
            "üìä Training Accuracy: 1.0000 (100.00%)\n",
            "\n",
            "üìã Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Employment       1.00      1.00      1.00         1\n",
            "         NDA       1.00      1.00      1.00         1\n",
            " Partnership       1.00      1.00      1.00         1\n",
            "     Service       1.00      1.00      1.00         1\n",
            "      Vendor       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "\n",
            "üéØ Sample predictions with confidence:\n",
            "  Document 1: Actual=Partnership, Predicted=Partnership, Confidence=0.330\n",
            "  Document 2: Actual=Vendor, Predicted=Vendor, Confidence=0.315\n",
            "  Document 3: Actual=Employment, Predicted=Employment, Confidence=0.307\n",
            "  Document 4: Actual=NDA, Predicted=NDA, Confidence=0.300\n",
            "  Document 5: Actual=Service, Predicted=Service, Confidence=0.288\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Train the classifier and evaluate\n",
        "print(\"ü§ñ Training Logistic Regression classifier...\")\n",
        "\n",
        "classifier = LogisticRegression(\n",
        "    random_state=42,\n",
        "    max_iter=2000,\n",
        "    class_weight='balanced',  # Handle class imbalance\n",
        "    C=1.0  # Regularization parameter\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "classifier.fit(X, labels)\n",
        "\n",
        "# Make predictions\n",
        "predictions = classifier.predict(X)\n",
        "accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "print(f\"‚úÖ Training complete!\")\n",
        "print(f\"üìä Training Accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(f\"\\nüìã Classification Report:\")\n",
        "print(classification_report(labels, predictions))\n",
        "\n",
        "# Show some example predictions with confidence\n",
        "print(f\"\\nüéØ Sample predictions with confidence:\")\n",
        "proba_predictions = classifier.predict_proba(X)\n",
        "for i in range(min(5, len(documents))):\n",
        "    actual = labels[i]\n",
        "    predicted = predictions[i]\n",
        "    confidence = np.max(proba_predictions[i])\n",
        "    print(f\"  Document {i+1}: Actual={actual}, Predicted={predicted}, Confidence={confidence:.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiK2AftzORTD",
        "outputId": "cecc3196-be89-40de-9e54-6a0c11e2ba56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Model saved as contract_classifier.pkl\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Save the trained model\n",
        "def save_model(tfidf, classifier, filename='models/TF_IDF_Logitic_Regression.pkl'):\n",
        "    \"\"\"Save the trained model\"\"\"\n",
        "    model_data = {\n",
        "        'tfidf': tfidf,\n",
        "        'classifier': classifier,\n",
        "        'classes': classifier.classes_\n",
        "    }\n",
        "\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(model_data, f)\n",
        "    print(f\"üíæ Model saved as {filename}\")\n",
        "\n",
        "save_model(tfidf, classifier)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL0_0iDCOt7O",
        "outputId": "fd5ac34a-c75d-4adc-9a4c-8d638449d91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Testing model on new examples:\n",
            "\n",
            "üìÑ Example 1:\n",
            "   Text: This employment agreement is between ABC Corp and John Doe f...\n",
            "   Prediction: Employment\n",
            "   Confidence: 0.225\n",
            "   Top predictions: [(np.str_('Employment'), '0.225'), (np.str_('Partnership'), '0.212'), (np.str_('NDA'), '0.192')]\n",
            "\n",
            "üìÑ Example 2:\n",
            "   Text: Confidential information disclosed under this Non-Disclosure...\n",
            "   Prediction: NDA\n",
            "   Confidence: 0.230\n",
            "   Top predictions: [(np.str_('NDA'), '0.230'), (np.str_('Partnership'), '0.202'), (np.str_('Employment'), '0.200')]\n",
            "\n",
            "üìÑ Example 3:\n",
            "   Text: The partnership between Smith and Jones will share all profi...\n",
            "   Prediction: Partnership\n",
            "   Confidence: 0.247\n",
            "   Top predictions: [(np.str_('Partnership'), '0.247'), (np.str_('NDA'), '0.194'), (np.str_('Vendor'), '0.192')]\n",
            "\n",
            "üìÑ Example 4:\n",
            "   Text: Vendor shall deliver goods pursuant to the following terms a...\n",
            "   Prediction: Vendor\n",
            "   Confidence: 0.209\n",
            "   Top predictions: [(np.str_('Vendor'), '0.209'), (np.str_('Employment'), '0.207'), (np.str_('Partnership'), '0.199')]\n",
            "\n",
            "üìÑ Example 5:\n",
            "   Text: Service Level Agreement: The provider guarantees 99.9% uptim...\n",
            "   Prediction: Service\n",
            "   Confidence: 0.208\n",
            "   Top predictions: [(np.str_('Service'), '0.208'), (np.str_('Partnership'), '0.202'), (np.str_('NDA'), '0.198')]\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Test the model on new examples\n",
        "def batch_predict(texts, tfidf, classifier):\n",
        "    \"\"\"Predict multiple documents at once\"\"\"\n",
        "    predictions = []\n",
        "    probabilities = []\n",
        "\n",
        "    for text in texts:\n",
        "        cleaned_text = advanced_preprocess_text(text)\n",
        "        text_vector = tfidf.transform([cleaned_text])\n",
        "\n",
        "        pred = classifier.predict(text_vector)[0]\n",
        "        prob = classifier.predict_proba(text_vector)[0]\n",
        "\n",
        "        predictions.append(pred)\n",
        "        probabilities.append(dict(zip(classifier.classes_, prob)))\n",
        "\n",
        "    return predictions, probabilities\n",
        "\n",
        "# Test with sample contracts\n",
        "test_contracts = [\n",
        "    \"This employment agreement is between ABC Corp and John Doe for the position of software engineer with a salary of $100,000 per year.\",\n",
        "    \"Confidential information disclosed under this Non-Disclosure Agreement must be kept secret by all parties for a period of 5 years.\",\n",
        "    \"The partnership between Smith and Jones will share all profits equally and both parties agree to contribute capital to the business.\",\n",
        "    \"Vendor shall deliver goods pursuant to the following terms and conditions outlined in this vendor agreement.\",\n",
        "    \"Service Level Agreement: The provider guarantees 99.9% uptime and will provide 24/7 support for all critical issues.\"\n",
        "]\n",
        "\n",
        "print(\"üß™ Testing model on new examples:\")\n",
        "batch_preds, batch_probs = batch_predict(test_contracts, tfidf, classifier)\n",
        "\n",
        "for i, (text, pred, prob) in enumerate(zip(test_contracts, batch_preds, batch_probs)):\n",
        "    print(f\"\\nüìÑ Example {i+1}:\")\n",
        "    print(f\"   Text: {text[:60]}...\")\n",
        "    print(f\"   Prediction: {pred}\")\n",
        "    print(f\"   Confidence: {prob[pred]:.3f}\")\n",
        "    # Show top 3 predictions\n",
        "    sorted_probs = sorted(prob.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "    print(f\"   Top predictions: {[(p, f'{c:.3f}') for p, c in sorted_probs]}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
